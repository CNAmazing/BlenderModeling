import onnxruntime as ort
import numpy as np
import cv2
import os
from typing import Tuple, Dict, List
from matplotlib import pyplot as plt
import sys
cwd = os.getcwd()
sys.path.append(cwd)
from Hw_Tools import *

def prepare_input(
    rgb_image: np.ndarray, input_size: Tuple[int, int]
) -> Tuple[Dict[str, np.ndarray], List[int]]:

    h, w = rgb_image.shape[:2]
    scale = min(input_size[0] / h, input_size[1] / w)
    rgb = cv2.resize(
        rgb_image, (int(w * scale), int(h * scale)), interpolation=cv2.INTER_LINEAR
    )

    padding = [123.675, 116.28, 103.53]
    h, w = rgb.shape[:2]
    pad_h = input_size[0] - h
    pad_w = input_size[1] - w
    pad_h_half = pad_h // 2
    pad_w_half = pad_w // 2
    rgb: np.ndarray = cv2.copyMakeBorder(
        rgb,
        pad_h_half,
        pad_h - pad_h_half,
        pad_w_half,
        pad_w - pad_w_half,
        cv2.BORDER_CONSTANT,
        value=padding,
    )
    pad_info = [pad_h_half, pad_h - pad_h_half, pad_w_half, pad_w - pad_w_half]

    onnx_input = {
        "pixel_values": np.ascontiguousarray(
            np.transpose(rgb, (2, 0, 1))[None], dtype=np.float32
        ),  # 1, 3, H, W
    }
    return onnx_input, pad_info

def Metric3d_Processing(onnx_model=None, input_image=None):
    
        # åˆ†è§£è·¯å¾„
    dir_path = os.path.dirname(input_image)  # èŽ·å–ç›®å½•è·¯å¾„: "output\Cube.001\images"
    base_name = os.path.basename(input_image)  # èŽ·å–æ–‡ä»¶å: "poly0.jpg"
    name_without_ext = os.path.splitext(base_name)[0]  # åŽ»é™¤æ‰©å±•å: "poly0"
    ## Dummy Test
    B = 1
    if "vit" in onnx_model:
        input_size = (616, 1064)  # [H, W]
        dummy_image = np.zeros([B, 3, input_size[0], input_size[1]], dtype=np.float32)
    else:
        input_size = (544, 1216)  # [H, W]
        dummy_image = np.zeros([B, 3, input_size[0], input_size[1]], dtype=np.float32)

    providers = [
        (
            "CUDAExecutionProvider",
            {"cudnn_conv_use_max_workspace": "0", "device_id": str(0)},
        )
    ]
    # providers = [("TensorrtExecutionProvider", {'trt_engine_cache_enable': True, 'trt_fp16_enable': True, 'device_id': 0, 'trt_dla_enable': False})]
    ort_session = ort.InferenceSession(onnx_model, providers=providers)
    outputs = ort_session.run(None, {"pixel_values": dummy_image})

    print(
        f"The actual output of onnxruntime session for the dummy set: outputs[0].shape={outputs[0].shape}"
    )

    ## Real Test
    rgb_image = cv2.imread(input_image)[:, :, ::-1]  # BGR to RGB
    original_shape = rgb_image.shape[:2]
    onnx_input, pad_info = prepare_input(rgb_image, input_size)
    outputs = ort_session.run(None, onnx_input)
    depth = outputs[0].squeeze()  # [H, W]
    normal=outputs[1].squeeze()  # [3,H, W]
    # Reshape the depth to the original size
    depth = depth[
        pad_info[0] : input_size[0] - pad_info[1],
        pad_info[2] : input_size[1] - pad_info[3],
    ]
    normal=normal[
        :,
        pad_info[0] : input_size[0] - pad_info[1],
        pad_info[2] : input_size[1] - pad_info[3],
    ]
    normal = np.transpose(normal, (1, 2, 0))  # [H,W,3]

    normal = cv2.resize(
        normal, (original_shape[1], original_shape[0]), interpolation=cv2.INTER_LINEAR
    )
    normal=(normal+1)/2
    normal = (normal * 255).astype(np.uint8)
    depth = cv2.resize(
        depth, (original_shape[1], original_shape[0]), interpolation=cv2.INTER_NEAREST
    )

    # plt.subplot(1, 3, 1)
    # plt.imshow(normal)
    
    # plt.subplot(1, 3, 2)
    # plt.imshow(depth)
    
    # plt.subplot(1, 3, 3)
    # plt.imshow(rgb_image)
    # plt.show()
    normal_output_Path= os.path.join(dir_path, f"{name_without_ext}_normal.jpg")
    depth_output_Path= os.path.join(dir_path, f"{name_without_ext}_depth.jpg")
    cv2.imwrite(normal_output_Path, normal)
    cv2.imwrite(depth_output_Path, depth)


 
 
class YOLO11:
    """YOLO11 ç›®æ ‡æ£€æµ‹æ¨¡åž‹ç±»ï¼Œç”¨äºŽå¤„ç†æŽ¨ç†å’Œå¯è§†åŒ–ã€‚"""
    def __init__(self, onnx_model, input_image, confidence_thres, iou_thres):
        """
        åˆå§‹åŒ– YOLO11 ç±»çš„å®žä¾‹ã€‚
        å‚æ•°ï¼š
            onnx_model: ONNX æ¨¡åž‹çš„è·¯å¾„ã€‚
            input_image: è¾“å…¥å›¾åƒçš„è·¯å¾„ã€‚
            confidence_thres: ç”¨äºŽè¿‡æ»¤æ£€æµ‹ç»“æžœçš„ç½®ä¿¡åº¦é˜ˆå€¼ã€‚
            iou_thres: éžæžå¤§å€¼æŠ‘åˆ¶ï¼ˆNMSï¼‰çš„ IoUï¼ˆäº¤å¹¶æ¯”ï¼‰é˜ˆå€¼ã€‚
        """
        self.onnx_model = onnx_model
        self.input_image = input_image
        self.confidence_thres = confidence_thres
        self.iou_thres = iou_thres
 
        # åŠ è½½ç±»åˆ«åç§°
        self.classes = CLASS_NAMES
 
        # ä¸ºæ¯ä¸ªç±»åˆ«ç”Ÿæˆä¸€ä¸ªé¢œè‰²è°ƒè‰²æ¿
        self.color_palette = np.random.uniform(0, 255, size=(len(self.classes), 3))
 
    def preprocess(self):
        """
        å¯¹è¾“å…¥å›¾åƒè¿›è¡Œé¢„å¤„ç†ï¼Œä»¥ä¾¿è¿›è¡ŒæŽ¨ç†ã€‚
        è¿”å›žï¼š
            image_data: ç»è¿‡é¢„å¤„ç†çš„å›¾åƒæ•°æ®ï¼Œå‡†å¤‡è¿›è¡ŒæŽ¨ç†ã€‚
        """
        # ä½¿ç”¨ OpenCV è¯»å–è¾“å…¥å›¾åƒ
        self.img = cv2.imread(self.input_image)
        # èŽ·å–è¾“å…¥å›¾åƒçš„é«˜åº¦å’Œå®½åº¦
        self.img_height, self.img_width = self.img.shape[:2]
 
        # å°†å›¾åƒé¢œè‰²ç©ºé—´ä»Ž BGR è½¬æ¢ä¸º RGB
        img = cv2.cvtColor(self.img, cv2.COLOR_BGR2RGB)
 
        # ä¿æŒå®½é«˜æ¯”ï¼Œè¿›è¡Œ letterbox å¡«å……, ä½¿ç”¨æ¨¡åž‹è¦æ±‚çš„è¾“å…¥å°ºå¯¸
        img, self.ratio, (self.dw, self.dh) = self.letterbox(img, new_shape=(self.input_width, self.input_height))
 
        # é€šè¿‡é™¤ä»¥ 255.0 æ¥å½’ä¸€åŒ–å›¾åƒæ•°æ®
        image_data = np.array(img) / 255.0
 
        # å°†å›¾åƒçš„é€šé“ç»´åº¦ç§»åˆ°ç¬¬ä¸€ç»´
        image_data = np.transpose(image_data, (2, 0, 1))  # é€šé“ä¼˜å…ˆ
 
        # æ‰©å±•å›¾åƒæ•°æ®çš„ç»´åº¦ï¼Œä»¥åŒ¹é…æ¨¡åž‹è¾“å…¥çš„å½¢çŠ¶
        image_data = np.expand_dims(image_data, axis=0).astype(np.float32)
 
        # è¿”å›žé¢„å¤„ç†åŽçš„å›¾åƒæ•°æ®
        return image_data
 
 
    def letterbox(self, img, new_shape=(640, 640), color=(114, 114, 114), auto=False, scaleFill=False, scaleup=True):
        """
        å°†å›¾åƒè¿›è¡Œ letterbox å¡«å……ï¼Œä¿æŒçºµæ¨ªæ¯”ä¸å˜ï¼Œå¹¶ç¼©æ”¾åˆ°æŒ‡å®šå°ºå¯¸ã€‚
        """
        shape = img.shape[:2]  # å½“å‰å›¾åƒçš„å®½é«˜
        print(f"Original image shape: {shape}")
 
        if isinstance(new_shape, int):
            new_shape = (new_shape, new_shape)
 
        # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹
        r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])  # é€‰æ‹©å®½é«˜ä¸­æœ€å°çš„ç¼©æ”¾æ¯”
        if not scaleup:  # ä»…ç¼©å°ï¼Œä¸æ”¾å¤§
            r = min(r, 1.0)
 
        # ç¼©æ”¾åŽçš„æœªå¡«å……å°ºå¯¸
        new_unpad = (int(round(shape[1] * r)), int(round(shape[0] * r)))
 
        # è®¡ç®—éœ€è¦çš„å¡«å……
        dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]  # è®¡ç®—å¡«å……çš„å°ºå¯¸
        dw /= 2  # padding å‡åˆ†
        dh /= 2
 
        # ç¼©æ”¾å›¾åƒ
        if shape[::-1] != new_unpad:  # å¦‚æžœå½“å‰å›¾åƒå°ºå¯¸ä¸ç­‰äºŽ new_unpadï¼Œåˆ™ç¼©æ”¾
            img = cv2.resize(img, new_unpad, interpolation=cv2.INTER_LINEAR)
 
        # ä¸ºå›¾åƒæ·»åŠ è¾¹æ¡†ä»¥è¾¾åˆ°ç›®æ ‡å°ºå¯¸
        top, bottom = int(round(dh)), int(round(dh))
        left, right = int(round(dw)), int(round(dw))
        img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)
        if img.shape[0] != new_shape[0] or img.shape[1] != new_shape[1]:
            img = cv2.resize(img, new_shape, interpolation=cv2.INTER_LINEAR)
        print(f"Final letterboxed image shape: {img.shape}")
 
        return img, (r, r), (dw, dh)
    def postprocess(self, input_image, output):
        """
        å¯¹æ¨¡åž‹è¾“å‡ºè¿›è¡ŒåŽå¤„ç†ï¼Œä»¥æå–è¾¹ç•Œæ¡†ã€åˆ†æ•°å’Œç±»åˆ« IDã€‚
        å‚æ•°ï¼š
            input_image (numpy.ndarray): è¾“å…¥å›¾åƒã€‚
            output (numpy.ndarray): æ¨¡åž‹çš„è¾“å‡ºã€‚
        è¿”å›žï¼š
            numpy.ndarray: åŒ…å«æ£€æµ‹ç»“æžœçš„è¾“å…¥å›¾åƒã€‚
        """
        # è½¬ç½®å¹¶åŽ‹ç¼©è¾“å‡ºï¼Œä»¥åŒ¹é…é¢„æœŸå½¢çŠ¶
        outputs = np.transpose(np.squeeze(output[0]))
        rows = outputs.shape[0]
        boxes, scores, class_ids = [], [], []
        # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹å’Œå¡«å……
        ratio = self.img_width / self.input_width, self.img_height / self.input_height
 
        for i in range(rows):
            classes_scores = outputs[i][4:]
            max_score = np.amax(classes_scores)
            if max_score >= self.confidence_thres:
                class_id = np.argmax(classes_scores)
                x, y, w, h = outputs[i][0], outputs[i][1], outputs[i][2], outputs[i][3]
 
                # å°†æ¡†è°ƒæ•´åˆ°åŽŸå§‹å›¾åƒå°ºå¯¸ï¼Œè€ƒè™‘ç¼©æ”¾å’Œå¡«å……
                x -= self.dw  # ç§»é™¤å¡«å……
                y -= self.dh
                x /= self.ratio[0]  # ç¼©æ”¾å›žåŽŸå›¾
                y /= self.ratio[1]
                w /= self.ratio[0]
                h /= self.ratio[1]
                left = int(x - w / 2)
                top = int(y - h / 2)
                width = int(w)
                height = int(h)
 
                boxes.append([left, top, width, height])
                scores.append(max_score)
                class_ids.append(class_id)

        indices = cv2.dnn.NMSBoxes(boxes, scores, self.confidence_thres, self.iou_thres)
        print('indices',indices)
        result_boxes = []
        result_scores = []
        result_class_ids = []
        for i in indices:
            box = boxes[i]
            score = scores[i]
            class_id = class_ids[i]
            result_boxes.append(box)
            result_scores.append(score)
            result_class_ids.append(class_id)
            self.draw_detections(input_image, box, score, class_id)
        result={
            'boxes':result_boxes,
            'scores':result_scores,
            'class_ids':result_class_ids
            }
        return result, input_image
    def draw_detections(self, img, box, score, class_id):
        """
        åœ¨è¾“å…¥å›¾åƒä¸Šç»˜åˆ¶æ£€æµ‹åˆ°çš„è¾¹ç•Œæ¡†å’Œæ ‡ç­¾ã€‚
        å‚æ•°ï¼š
            img: ç”¨äºŽç»˜åˆ¶æ£€æµ‹ç»“æžœçš„è¾“å…¥å›¾åƒã€‚
            box: æ£€æµ‹åˆ°çš„è¾¹ç•Œæ¡†ã€‚
            score: å¯¹åº”çš„æ£€æµ‹åˆ†æ•°ã€‚
            class_id: æ£€æµ‹åˆ°çš„ç›®æ ‡ç±»åˆ« IDã€‚
        
        è¿”å›žï¼š
            None
        """
        # æå–è¾¹ç•Œæ¡†çš„åæ ‡
        x1, y1, w, h = box
 
        # èŽ·å–ç±»åˆ«å¯¹åº”çš„é¢œè‰²
        color = self.color_palette[class_id]
 
        # åœ¨å›¾åƒä¸Šç»˜åˆ¶è¾¹ç•Œæ¡†
        cv2.rectangle(img, (int(x1), int(y1)), (int(x1 + w), int(y1 + h)), color, 2)
 
        # åˆ›å»ºåŒ…å«ç±»åˆ«åå’Œåˆ†æ•°çš„æ ‡ç­¾æ–‡æœ¬
        label = f"{self.classes[class_id]}: {score:.2f}"
 
        # è®¡ç®—æ ‡ç­¾æ–‡æœ¬çš„å°ºå¯¸
        (label_width, label_height), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)
 
        # è®¡ç®—æ ‡ç­¾æ–‡æœ¬çš„ä½ç½®
        label_x = x1
        label_y = y1 - 10 if y1 - 10 > label_height else y1 + 10
 
        # ç»˜åˆ¶å¡«å……çš„çŸ©å½¢ä½œä¸ºæ ‡ç­¾æ–‡æœ¬çš„èƒŒæ™¯
        cv2.rectangle(img, (label_x, label_y - label_height), (label_x + label_width, label_y + label_height), color, cv2.FILLED)
 
        # åœ¨å›¾åƒä¸Šç»˜åˆ¶æ ‡ç­¾æ–‡æœ¬
        cv2.putText(img, label, (label_x, label_y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)
 
 
    def main(self):
        # ä½¿ç”¨ ONNX æ¨¡åž‹åˆ›å»ºæŽ¨ç†ä¼šè¯ï¼Œè‡ªåŠ¨é€‰æ‹©CPUæˆ–GPU
        session = ort.InferenceSession(
            self.onnx_model, 
            providers=["CUDAExecutionProvider", "CPUExecutionProvider"] if ort.get_device() == "GPU" else ["CPUExecutionProvider"],
        )
        # æ‰“å°æ¨¡åž‹çš„è¾“å…¥å°ºå¯¸
        print("YOLO11 ðŸš€ ç›®æ ‡æ£€æµ‹ ONNXRuntime")
        print("æ¨¡åž‹åç§°ï¼š", self.onnx_model)
        
        # èŽ·å–æ¨¡åž‹çš„è¾“å…¥å½¢çŠ¶
        model_inputs = session.get_inputs()
        input_shape = model_inputs[0].shape  
        self.input_width = input_shape[2]
        self.input_height = input_shape[3]
        print(f"æ¨¡åž‹è¾“å…¥å°ºå¯¸ï¼šå®½åº¦ = {self.input_width}, é«˜åº¦ = {self.input_height}")
 
        # é¢„å¤„ç†å›¾åƒæ•°æ®ï¼Œç¡®ä¿ä½¿ç”¨æ¨¡åž‹è¦æ±‚çš„å°ºå¯¸ (640x640)
        img_data = self.preprocess()
       
        # ä½¿ç”¨é¢„å¤„ç†åŽçš„å›¾åƒæ•°æ®è¿è¡ŒæŽ¨ç†
        outputs = session.run(None, {model_inputs[0].name: img_data})
 
        # å¯¹è¾“å‡ºè¿›è¡ŒåŽå¤„ç†ä»¥èŽ·å–è¾“å‡ºå›¾åƒ
        return self.postprocess(self.img, outputs)  # è¾“å‡ºå›¾åƒ
class YOLO11_glass(YOLO11):
    def __init__(self, onnx_model, input_image, confidence_thres, iou_thres):
        super().__init__(onnx_model, input_image, confidence_thres, iou_thres)
        self.color_palette= {0: 'glass', }
        self.color_palette = np.random.uniform(0, 255, size=(len(self.classes), 3))
    """YOLO11 ç›®æ ‡æ£€æµ‹æ¨¡åž‹ç±»ï¼Œç”¨äºŽå¤„ç†æŽ¨ç†å’Œå¯è§†åŒ–ã€‚"""
    def preprocess(self):
        """
        å¯¹è¾“å…¥å›¾åƒè¿›è¡Œé¢„å¤„ç†ï¼Œä»¥ä¾¿è¿›è¡ŒæŽ¨ç†ã€‚
        è¿”å›žï¼š
            image_data: ç»è¿‡é¢„å¤„ç†çš„å›¾åƒæ•°æ®ï¼Œå‡†å¤‡è¿›è¡ŒæŽ¨ç†ã€‚
        """
        self.img = self.input_image
        # èŽ·å–è¾“å…¥å›¾åƒçš„é«˜åº¦å’Œå®½åº¦
        self.img_height, self.img_width = self.input_image.shape[:2]
 
        # å°†å›¾åƒé¢œè‰²ç©ºé—´ä»Ž BGR è½¬æ¢ä¸º RGB
        img = cv2.cvtColor(self.img, cv2.COLOR_BGR2RGB)
 
        # ä¿æŒå®½é«˜æ¯”ï¼Œè¿›è¡Œ letterbox å¡«å……, ä½¿ç”¨æ¨¡åž‹è¦æ±‚çš„è¾“å…¥å°ºå¯¸
        img, self.ratio, (self.dw, self.dh) = self.letterbox(img, new_shape=(self.input_width, self.input_height))
 
        # é€šè¿‡é™¤ä»¥ 255.0 æ¥å½’ä¸€åŒ–å›¾åƒæ•°æ®
        image_data = np.array(img) / 255.0
 
        # å°†å›¾åƒçš„é€šé“ç»´åº¦ç§»åˆ°ç¬¬ä¸€ç»´
        image_data = np.transpose(image_data, (2, 0, 1))  # é€šé“ä¼˜å…ˆ
 
        # æ‰©å±•å›¾åƒæ•°æ®çš„ç»´åº¦ï¼Œä»¥åŒ¹é…æ¨¡åž‹è¾“å…¥çš„å½¢çŠ¶
        image_data = np.expand_dims(image_data, axis=0).astype(np.float32)
 
        # è¿”å›žé¢„å¤„ç†åŽçš„å›¾åƒæ•°æ®
        return image_data
 
    def letterbox(self, img, new_shape=(256, 256), color=(114, 114, 114), auto=False, scaleFill=False, scaleup=True):
        """
        å°†å›¾åƒè¿›è¡Œ letterbox å¡«å……ï¼Œä¿æŒçºµæ¨ªæ¯”ä¸å˜ï¼Œå¹¶ç¼©æ”¾åˆ°æŒ‡å®šå°ºå¯¸ã€‚
        """
        shape = img.shape[:2]  # å½“å‰å›¾åƒçš„å®½é«˜
        print(f"Original image shape: {shape}")
 
        if isinstance(new_shape, int):
            new_shape = (new_shape, new_shape)
 
        # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹
        r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])  # é€‰æ‹©å®½é«˜ä¸­æœ€å°çš„ç¼©æ”¾æ¯”
        if not scaleup:  # ä»…ç¼©å°ï¼Œä¸æ”¾å¤§
            r = min(r, 1.0)
 
        # ç¼©æ”¾åŽçš„æœªå¡«å……å°ºå¯¸
        new_unpad = (int(round(shape[1] * r)), int(round(shape[0] * r)))
 
        # è®¡ç®—éœ€è¦çš„å¡«å……
        dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]  # è®¡ç®—å¡«å……çš„å°ºå¯¸
        dw /= 2  # padding å‡åˆ†
        dh /= 2
 
        # ç¼©æ”¾å›¾åƒ
        if shape[::-1] != new_unpad:  # å¦‚æžœå½“å‰å›¾åƒå°ºå¯¸ä¸ç­‰äºŽ new_unpadï¼Œåˆ™ç¼©æ”¾
            img = cv2.resize(img, new_unpad, interpolation=cv2.INTER_LINEAR)
 
        # ä¸ºå›¾åƒæ·»åŠ è¾¹æ¡†ä»¥è¾¾åˆ°ç›®æ ‡å°ºå¯¸
        top, bottom = int(round(dh)), int(round(dh))
        left, right = int(round(dw)), int(round(dw))
        img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)
        if img.shape[0] != new_shape[0] or img.shape[1] != new_shape[1]:
            img = cv2.resize(img, new_shape, interpolation=cv2.INTER_LINEAR)
        print(f"Final letterboxed image shape: {img.shape}")
 
        return img, (r, r), (dw, dh)
    
def get_jpg_paths(folder_name):
    """
    èŽ·å–æŒ‡å®šæ–‡ä»¶å¤¹ä¸‹imageså­ç›®å½•ä¸­çš„æ‰€æœ‰.jpgå›¾ç‰‡è·¯å¾„åŠä¸å¸¦åŽç¼€çš„æ–‡ä»¶å
    
    å‚æ•°:
        folder_name (str): ç›®æ ‡æ–‡ä»¶å¤¹åç§°ï¼ˆå¦‚"x"ï¼‰
        
    è¿”å›ž:
        tuple: (å®Œæ•´è·¯å¾„åˆ—è¡¨, ä¸å¸¦åŽç¼€çš„æ–‡ä»¶ååˆ—è¡¨)ï¼Œå¦‚(
                ["x/images/pic1.jpg", "x/images/pic2.jpg"], 
                ["pic1", "pic2"]
               )
    """
    full_paths = []
    basenames = []
    
    try:
        images_dir = os.path.join(folder_name, "images")
        if not os.path.exists(images_dir):
            raise FileNotFoundError(f"ç›®å½•ä¸å­˜åœ¨: {images_dir}")
            
        for f in os.listdir(images_dir):
            if f.lower().endswith(".jpg"):
                file_path = os.path.join(images_dir, f)
                if os.path.isfile(file_path):
                    full_paths.append(file_path)
                    # åŽ»æŽ‰.jpgåŽç¼€èŽ·å–çº¯æ–‡ä»¶å
                    basenames.append(os.path.splitext(f)[0])
                    
        return full_paths, basenames
        
    except Exception as e:
        print(f"é”™è¯¯: {e}")
        return [], []
CLASS_NAMES = {
    0: 'window',   # ç±»åˆ« 0 åç§°
    1: 'balcony',   # ç±»åˆ« 1 åç§°
    2: 'door'    # ç±»åˆ« 1 åç§°
                        # å¯ä»¥æ·»åŠ æ›´å¤šç±»åˆ«...
}
TOTAL_CLASSES=['window','door','glass']
def main():
    input_folder = "output\Cube.001"
    jps_paths,basenames=get_jpg_paths(input_folder)
    json_path=os.path.join(input_folder,'data.json')
    poly_dict=read_json(json_path)

    #åˆ é™¤é‡å¤ç”Ÿæˆçš„box
    for poly in poly_dict.values():
        for cls in TOTAL_CLASSES:
            poly.pop(cls, None)
    #è¯»å–æ¯ä¸ªå›¾åƒè¿›è¡ŒMetric3då’ŒYOLOå¤„ç†   
    for image_path,basename in zip(jps_paths, basenames):
        
        # å¤„ç†æ¯ä¸ªå›¾ç‰‡
        Metric3d_Processing(onnx_model="checkpoint\Metric3d_vit_small.onnx",
                            input_image=image_path
            )
        
        facade_detection = YOLO11( onnx_model="checkpoint\YOLO_window.onnx",
                            input_image=image_path,
                            confidence_thres=0.5,
                            iou_thres=0.25,
            )
        facade_Params={
            'window':[],
            'glass':[],
            'door':[],
        }

        facade_result,output_image = facade_detection.main()
        image = cv2.imread(image_path)
        # èŽ·å–è¾“å…¥å›¾åƒçš„é«˜åº¦å’Œå®½åº¦

        for i in range(len(facade_result['boxes'])):
            box = facade_result['boxes'][i]
            score = facade_result['scores'][i]
            class_id = facade_result['class_ids'][i]
            facade_Params[CLASS_NAMES[class_id]].append(box)

            if CLASS_NAMES[class_id] == 'window':
                window_x1, window_y1, window_w, window_h = box
                glass_detection = YOLO11_glass( onnx_model="checkpoint\YOLO_glass.onnx",
                            input_image=image[window_y1:window_y1+window_h,window_x1:window_x1+window_w,: ],
                            confidence_thres=0.5,
                            iou_thres=0.25,
                            )
                glass_result,glass_output_image = glass_detection.main()
                for j in range(len(glass_result['boxes'])):
                    g_box= glass_result['boxes'][j]
                    g_box[0] += window_x1
                    g_box[1] += window_y1
                    facade_Params['glass'].append(g_box)
        
        #ç»™poly_dictæ·»åŠ æ•°æ®
        for key, value in facade_Params.items():
            if value:
                poly_dict[basename][key]=value
        
    """
    ä¿å­˜ä¸ºjsonæ–‡ä»¶
    """
    with open(json_path, "w") as json_file:
        json.dump(poly_dict, json_file, indent=4)
    
    # """
    # Metric3D Processingåªå¤„ç†å•å›¾åƒ
    # """
    # Metric3d_Processing(
    # onnx_model="checkpoint\Metric3d_large.onnx",
    # input_image="output\poly0_.jpg"
    # )

    # """
    # YOLO Processing
    # åªå¤„ç†å•å›¾åƒ
    # """
    # detection = YOLO11(
    #     onnx_model="checkpoint\YOLO_window.onnx",
    #     input_image="output\poly0_.jpg",
    #     confidence_thres=0.25,
    #     iou_thres=0.45,
    # )
    # """"
    # result-â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”>å­—å…¸
    # 'boxes': æ£€æµ‹åˆ°çš„è¾¹ç•Œæ¡†åˆ—è¡¨
    # 'scores': å¯¹åº”çš„æ£€æµ‹åˆ†æ•°åˆ—è¡¨
    # 'class_ids': æ£€æµ‹åˆ°çš„ç›®æ ‡ç±»åˆ« ID åˆ—è¡¨
    # """
    # result,output_image = detection.main()
    
main()
print("Done!")
